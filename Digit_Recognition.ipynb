{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle_out= open(\"./model_trained.p\",\"wb\")\n",
        "pickle.dump(model,pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "qYmxZD7i7UVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ozaBru7Mt8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def zoom(img, zoom_factor=3):\n",
        "    return cv2.resize(img, None, fx=zoom_factor, fy=zoom_factor)\n",
        "\n",
        "img = cv2.imread(\"/content/gdrive/MyDrive/IITD/DigitRecognition/C2.tif\")\n",
        "pickle_in= open(\"/content/gdrive/MyDrive/IITD/DigitRecognition/model_trained.p\",\"rb\")\n",
        "model= pickle.load(pickle_in)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "img=cv2.resize(img,(1000,1000))\n",
        "\n",
        "grey = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "kernel = np.array([[0, -1, 0],\n",
        "                   [-1, 5,-1],\n",
        "                   [0, -1, 0]])\n",
        "grey = cv2.filter2D(src=grey, ddepth=-1, kernel=kernel)\n",
        "\n",
        "\n",
        "ret, thresh = cv2.threshold(grey, 156, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "cv2_imshow(thresh)\n",
        "\n",
        "final_digits = []\n",
        "centers=[]\n",
        "rec=[]\n",
        "\n",
        "while True:\n",
        "  r = cv2.selectROI(\"select the area\", thresh)\n",
        "  cropped= thresh[int(r[1]):int(r[1]+r[3]),\n",
        "                        int(r[0]):int(r[0]+r[2])]\n",
        "  cv2_imshow(cropped_image)\n",
        "\n",
        "  cropped= np.asarray(cropped_image)\n",
        "  cropped= cv2.resize(cropped_image,(32,32))\n",
        "  cropped=cropped_image/255\n",
        "  cropped= cropped_image.reshape(1,32,32,1)\n",
        "  contours,_ = cv2.findContours(cropped, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  X=[]\n",
        "\n",
        "  for c in contours:\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "      X.append((x,y))\n",
        "      area= cv2.contourArea(c)\n",
        "      if area > 15:\n",
        "\n",
        "          cv2.rectangle(img, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
        "          digit = thresh[y:y+h, x:x+w]\n",
        "          resized_digit = cv2.resize(digit, (18,18))\n",
        "          padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
        "          final_digits.append(padded_digit)\n",
        "\n",
        "  plt.imshow(img, cmap=\"gray\")\n",
        "  plt.show()\n",
        "\n",
        "  zoom= zoom(img)\n",
        "  cv2.imshow(\"zoom\",zoom)\n",
        "  for i in range(len(final_digits)):\n",
        "\n",
        "    f_img= final_digits[i].reshape(1,28,28,1)\n",
        "    prediction= model.predict(f_img)\n",
        "\n",
        "    cv2.putText(img, f\"{prediction}\", (X[i][1]-1,X[i][0]-1), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                 (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "  k=cv2.waitKey(0)\n",
        "  if k==27:\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "'''\n",
        "cv2.waitKey(0)\n"
      ]
    }
  ]
}